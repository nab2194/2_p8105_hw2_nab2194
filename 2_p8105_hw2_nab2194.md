Homework 2
================
Natalie Boychuk (nab2194)
September 27 2020

``` r
library(tidyverse)
```

    ## ── Attaching packages ──────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ─────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
options(digits = 2)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
    read_xlsx(
        path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "Mr. Trash Wheel",
        range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls)
    )
```

Read precipitation data for 2017/2018\!

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1) %>% 
        janitor::clean_names() %>% 
        drop_na(month) %>% 
        mutate(year = 2018) %>% 
        relocate(year) 

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1) %>% 
        janitor::clean_names() %>% 
        drop_na(month) %>% 
        mutate(year = 2017) %>% 
        relocate(year) 
```

Combine annual precipitation

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name 
  ) 

precip_df = 
  bind_rows(precip_2018, precip_2017) %>%  view

precip_df =
    left_join(precip_df, month_df, by = "month") 
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, including some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data. The
total precipitation in 2018 was 70.33 inches and the median number of
sports balls found in a dumpster in 2017 was 8.

## Problem 2

``` r
subway_df = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") 
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
  subway_df = janitor::clean_names(subway_df) %>%  
  select(line:entry, vending, ada) %>% 
    mutate(entry = recode(entry, YES = "TRUE", NO = "FALSE")) %>% 
    mutate(entry = as.logical(entry))
```

This dataset provides data on subway entrances/exits in New York City,
including ADA compliance, entrance type, vending, and routes served at
the station. The original dataset had 1868 rows and 19 columns after I
removed the variables I didn’t want for this analysis. In order to clean
this data, I reformatted the data to create two distinct variables for
route number and route name, which were previously represented across
multiple columns. I also cleaned up variable names to remove upper-case
in titles. The dataset is relatively cleaner than when I started the
data wrangling process, since every value has a cell, the variables are
in columns, and the observations are in rows.Some more work could be
done to improve the tidyness of the “Station Name” and “Line” variables,
which include in some cases Street or Avenue, as well as a mix of
numbers and letters.

``` r
subway_df %>% 
  filter(entry == "TRUE",
         vending == "NO") %>% 
  nrow
```

    ## [1] 69

``` r
subway_df %>% 
  filter(vending == "NO") %>% 
  nrow
```

    ## [1] 183

``` r
69/183 
```

    ## [1] 0.38

``` r
subway_df %>% 
  filter(ada == TRUE) %>% 
  distinct(station_name, line)
```

    ## # A tibble: 84 x 2
    ##    line            station_name                  
    ##    <chr>           <chr>                         
    ##  1 4 Avenue        Atlantic Av-Barclays Ctr      
    ##  2 4 Avenue        DeKalb Av                     
    ##  3 4 Avenue        Pacific St                    
    ##  4 42nd St Shuttle Grand Central                 
    ##  5 6 Avenue        34th St                       
    ##  6 6 Avenue        47-50th Sts Rockefeller Center
    ##  7 6 Avenue        Church Av                     
    ##  8 63rd Street     21st St                       
    ##  9 63rd Street     Lexington Av                  
    ## 10 63rd Street     Roosevelt Island              
    ## # … with 74 more rows

``` r
distinct(subway_df, station_name, line)
```

    ## # A tibble: 465 x 2
    ##    line     station_name            
    ##    <chr>    <chr>                   
    ##  1 4 Avenue 25th St                 
    ##  2 4 Avenue 36th St                 
    ##  3 4 Avenue 45th St                 
    ##  4 4 Avenue 53rd St                 
    ##  5 4 Avenue 59th St                 
    ##  6 4 Avenue 77th St                 
    ##  7 4 Avenue 86th St                 
    ##  8 4 Avenue 95th St                 
    ##  9 4 Avenue 9th St                  
    ## 10 4 Avenue Atlantic Av-Barclays Ctr
    ## # … with 455 more rows

``` r
clean_subway_df = subway_df %>% 
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)
         ) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_no",
    values_to = "route_name",
    names_prefix = "route"
    ) 
```

``` r
clean_subway_df %>% 
  filter(route_name == "A") %>% 
  distinct(station_name, line)
```

    ## # A tibble: 60 x 2
    ##    line            station_name                 
    ##    <chr>           <chr>                        
    ##  1 42nd St Shuttle Times Square                 
    ##  2 8 Avenue        125th St                     
    ##  3 8 Avenue        145th St                     
    ##  4 8 Avenue        14th St                      
    ##  5 8 Avenue        168th St - Washington Heights
    ##  6 8 Avenue        175th St                     
    ##  7 8 Avenue        181st St                     
    ##  8 8 Avenue        190th St                     
    ##  9 8 Avenue        34th St                      
    ## 10 8 Avenue        42nd St                      
    ## # … with 50 more rows

``` r
clean_subway_df %>%
  filter(route_name == "A",
         ada == "TRUE") %>% 
  distinct(station_name, line) %>% 
  count(station_name, line) 
```

    ## # A tibble: 17 x 3
    ##    station_name                  line                 n
    ##    <chr>                         <chr>            <int>
    ##  1 14th St                       8 Avenue             1
    ##  2 168th St - Washington Heights 8 Avenue             1
    ##  3 175th St                      8 Avenue             1
    ##  4 34th St                       8 Avenue             1
    ##  5 42nd St                       8 Avenue             1
    ##  6 59th St                       8 Avenue             1
    ##  7 59th St-Columbus Circle       Broadway-7th Ave     1
    ##  8 8th Av                        Canarsie             1
    ##  9 Euclid Av                     Fulton               1
    ## 10 Franklin Av                   Franklin             1
    ## 11 Franklin Av                   Fulton               1
    ## 12 Howard Beach                  Rockaway             1
    ## 13 Inwood - 207th St             8 Avenue             1
    ## 14 Times Square                  Broadway-7th Ave     1
    ## 15 Times Square-42nd St          Broadway             1
    ## 16 West 4th St                   8 Avenue             1
    ## 17 World Trade Center            8 Avenue             1

  - There are a total of 465 distinct subway stations in NYC. Of those,
    84 distinct stations are ADA compliant.
  - There are 69 station entrance/exits that allow entrance and do not
    have vending out of 183 total stations that do not have vending
    (37.7 of entrances without vending).
  - 60 distinct stations serve the A train; of those, 17 distinct
    stations are ADA compliant.

## Problem 3

``` r
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") 
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
clean_pols_month = pols_month %>% 
  separate(mon, into = c("year","month","day")) %>% 
  mutate(month = as.numeric(month))  
  
helper_pols_df = 
  tibble(
    month = 1:12,
    month_name = month.name) %>% 
    mutate(month = as.numeric(month)) 
    
joined_pols_month = left_join(clean_pols_month, helper_pols_df, by = "month") 

##created an intermediate df to join
interm_pols_month = joined_pols_month %>% 
  mutate(president = case_when(
    prez_gop == 1 ~ "gop",
    prez_dem == 1 ~ "dem")) %>% 
    select(-prez_gop, -prez_dem, -month, -day) %>% 
    relocate(month_name, .after = year) 
```

``` r
snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
clean_snp_df = snp_df %>% 
  separate(date, into =
           c("month","day","year")) %>% 
  mutate(month = as.numeric(month)) 
 
helper_snp_df = 
  tibble(
    month = 1:12,
    month_name = month.name) %>% 
    mutate(month = as.numeric(month))

##created an intermediate df to join
joined_snp_df = left_join(clean_snp_df, helper_snp_df, by = "month") %>% 
  relocate(month_name, .after = year)

interm_snp_df = joined_snp_df %>% 
   select(-month, -day) 
```

``` r
unemploy = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec, 
    names_to = "month",
    values_to = "perc_unemploy"
  ) 
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
clean_unemploy = unemploy %>% 
   mutate(month = recode(month, jan = "January", feb = "February", mar = "March", apr = "April", may = "May", jun = "June", jul = "July", aug = "August", sep = "September", oct = "October", nov = "November", dec = "Decmber")) %>% 
  rename(month_name = month) 

##created an intermediate df to join
interm_unemploy = clean_unemploy %>% 
mutate(year = as.character(year)) 
```

``` r
join_interm_df =
  left_join(interm_pols_month, interm_snp_df) 
```

    ## Joining, by = c("year", "month_name")

``` r
final_pols_month =  
  left_join(join_interm_df, interm_unemploy)
```

    ## Joining, by = c("year", "month_name")

``` r
view(final_pols_month) 
```

This dataset combines information from 3 separate datasets, which have
been joined together. The first dataset, pols\_month, had 822
observations and 9 variables related to the political affiliation of
governors, senators, and presidents. This was joined with the snp
dataset, which originally contained 787 observations and 2 variables
related to the Standard & Poor’s stock market index. These two datasets
were joined with the unemploy dataset, which contained 68 observations
and 13 variables related to the percentage of the population unemployed
at a given time.

I had to tidy these datasets in order to be able to join them:

  - For the pols\_month dataset, I first separated out the date variable
    to render three separate variables: month, date, and year. I created
    a “helper tibble” (helper\_pols\_df) to create a month variable
    using the month name, which I then joined to my pols\_month dataset.
    Because joins require consistent variable types I had to convert the
    month variable in pols\_month using the as.numeric function to make
    sure that it was consistent. Then, I created a new variable for
    “president” using conditional arguments and deleted variables I
    didn’t need.

  - For the snp dataset, I followed almost the same process as above.
    After joining my month variable to my dataset, I removed variables I
    didn’t want and arranged the table so that year/month columns were
    listed first.

  - For the unemployment data, first I made the table longer to ensure
    that the months were values in the same column rather than being
    spread over multiple columns. I recoded months to ensure the values
    were consistent with my other two dataframes, since this is
    important for joining.

After joining the three datasets, I was left with a dataset with 822
rows and 11 columns. It contains information about political affiliation
of politicians (including senators, governors, and presidents), the
state of the stock market, and the unemployment rate from NA to NA. This
dataset also includes disaggregated by month.
